---
lesson_id: "04-quality-operations"
lesson_title: "AI Quality, Security, and Operations"
source_dir: "mswd/04-quality-operations"
step_count: 10
---

<!-- STEP:01 -->
## Step 01: Why Guardrails Matter More Than Ever

# Why Guardrails Matter More Than Ever

Kick off by grounding yourself in reality: bugs destroy trust and burn cash. Isaac Evans from Semgrep points out that once LLMs write most of your code, you must assume higher defect rates. Classic threats (SQL injection, XSS, broken auth, IDOR, config mistakes) now have more surfaces because agents call tools autonomously. The way forward is not to slow down but to pair AI velocity with disciplined guardrails.

## Step Quiz
**Questions**
1) Why does increased AI-generated code heighten the need for guardrails?
**Answers**
1) Because more autogenerated changes raise the chance of regressions or vulnerabilities unless you enforce strong testing and security practices.

<!-- STEP:02 -->
## Step 02: Static Analysis (SAST)

# Static Analysis (SAST)

Static Application Security Testing is your first safety net. Run Semgrep, Bandit, or ESLint rules on source/binaries **before** the code runs to catch SQL injection, command injection, or XSS patterns. Findings are cheap to fix early, and you can wire these scans into your agent workflows so every diff—human or AI—gets vetted automatically. Tune rules carefully to avoid noise, but don’t skip this stage.

## Step Quiz
**Questions**
1) What types of vulnerabilities does SAST excel at catching?
**Answers**
1) Static code flaws such as SQL injection, command injection, and cross-site scripting patterns.

<!-- STEP:03 -->
## Step 03: Dynamic Analysis (DAST)

# Dynamic Analysis (DAST)

DAST complements SAST by treating your app like a black box. Fuzz inputs, tamper with tokens, brute force rate limits, or inspect headers while the service is running. Because you’re observing real behavior, false positives drop, and you can run these checks continuously in staging or production mirrors. When the AI forgets a validation step, DAST is often the mechanism that catches it before customers do.

## Step Quiz
**Questions**
1) Why does DAST tend to report fewer false positives than SAST?
**Answers**
1) It observes actual runtime behavior, so findings usually correspond to exploitable flaws rather than theoretical patterns.

<!-- STEP:04 -->
## Step 04: Software Composition Analysis (SCA)

# Software Composition Analysis (SCA)

SCA tracks the third-party code you ship. Scan package manifests, IaC files, and container images, resolve transitive dependencies, and match them against CVE databases. AI can introduce new packages without human review, so automated SCA ensures compromised libraries never make it to production unnoticed.

## Step Quiz
**Questions**
1) What does SCA analyze that SAST/DAST typically do not?
**Answers**
1) The open-source components and dependencies your application includes, including transitive packages and container images.

<!-- STEP:05 -->
## Step 05: New AI Attack Vectors

# New AI Attack Vectors

Agents open doors to attacks we rarely faced before:

- **Prompt injection** – hide malicious text in files/HTML so the model disobeys instructions.
- **Tool misuse** – trick the agent into abusing its own integrations.
- **Intent breaking** – manipulate the plan midstream and redirect actions.
- **Identity spoofing** – compromise auth tokens to impersonate agents.
- **Code attacks** – exploit the agent’s ability to run commands and escape sandboxes.

You need training, monitoring, and sandboxing strategies specifically for these vectors.

## Step Quiz
**Questions**
1) Give two examples of attack vectors unique to agentic systems.
**Answers**
1) Prompt injection (hidden instructions) and tool misuse (tricking the agent into abusing an integrated tool).

<!-- STEP:06 -->
## Step 06: LLMs for Security and Testing

# LLMs for Security and Testing

AI isn’t just a risk; it’s a force multiplier for AppSec. Use LLMs to triage SAST findings, draft penetration test plans, or generate regression tests automatically. Still, temper expectations: false positives can reach 50–100%, runs can disagree, and context windows lose fidelity over time. Always capture evidence, compact summaries responsibly, and keep humans in the loop for final sign-off.

## Step Quiz
**Questions**
1) What is a major limitation of today’s AI-driven security analysis?
**Answers**
1) High false-positive rates and inconsistent reasoning across runs make it risky to trust without human review.

<!-- STEP:07 -->
## Step 07: The Value of Code Review

# The Value of Code Review

Code review remains one of the highest leverage activities you can do. Studies cited by Tomas Reimers show 55–60% error detection rates compared to 25–45% for other testing modes, and defects per 100 lines plummet when review is standard practice. Good reviews:

- Reference specific lines or functions
- Explain why something is risky
- Offer alternatives or questions instead of “looks bad”

AI can draft the code, but humans still own the result when it reaches production.

## Step Quiz
**Questions**
1) Name two qualities of a good code review comment.
**Answers**
1) It references concrete code and proposes a rationale or potential resolution rather than vague criticism.

<!-- STEP:08 -->
## Step 08: AI-Augmented Code Review

# AI-Augmented Code Review

Modern tools (Graphite, Greptile, Coderabbit, Claude Code) augment review by:

- Flagging missing tests or risky patterns
- Summarizing diffs so humans focus on architecture
- Providing consistent enforcement of style guides

They also introduce trade-offs: setup/configuration overhead, false positives, and blind spots in domain-specific logic. Use them as companion reviewers that free humans to focus on nuance, not as automated merge buttons.

## Step Quiz
**Questions**
1) What should developers remain cautious about when using AI for code review?
**Answers**
1) AI often misses complex business logic or security nuances, so humans must still make the final quality call.

<!-- STEP:09 -->
## Step 09: The Old World of DevOps

# The Old World of DevOps

Shift gears to operations. Classic SRE life revolves around the **four golden signals** (latency, errors, traffic, saturation), on-call rotations, and runbooks that often lag reality. A typical incident playbook:

1. Acknowledge the page
2. Check database and app dashboards
3. Identify recent deploys or config changes
4. Localize the blast radius
5. Apply mitigations
6. Stabilize, monitor, and communicate updates every 10–15 minutes
7. Document root cause and follow-ups

Metrics like MTTR and number of engineers per incident define success.

## Step Quiz
**Questions**
1) What are the “four golden signals” every SRE monitors?
**Answers**
1) Latency, errors, traffic (requests/second), and saturation (resource usage).

<!-- STEP:10 -->
## Step 10: AI DevOps and the New World

# AI DevOps and the New World

Now watch AI reshape operations. Platforms such as Resolve AI, Datadog Bits AI, and Splunk Observability Assistant build dynamic knowledge graphs across services, correlate traces/logs/metrics, and narrate likely root causes with evidence. You still need to apply mitigations, but diagnosis accelerates dramatically. Key principles:

- Emphasize explainability so humans trust the agent’s suggestions
- Instrument everything; AI can’t reason about signals you never collected
- Recognize limits: heterogeneous stacks and complex incidents still require human judgment

The long-term goal is auto-remediation, but today the win is faster, evidence-backed triage.

## Step Quiz
**Questions**
1) What is the immediate value AI DevOps agents provide today?
**Answers**
1) They accelerate root cause analysis by correlating telemetry and presenting evidence-backed narratives, even if humans still apply the fixes.
