---
lesson_id: "03-agent-memory"
lesson_title: "Agent Memory"
source_dir: "reference-course/mastra/03-agent-memory"
step_count: 30
---

<!-- STEP:01 -->
## Step 01: Understanding Memory in Mastra

# Understanding Memory in Mastra

In this lesson, we'll explore how to enhance your Mastra agents with memory capabilities. Memory allows agents to maintain context across conversations, remember user preferences, and provide more personalized responses.

## What is Agent Memory?

Memory in Mastra is how agents manage the context that's available to them during conversations. It's essentially a condensation of chat messages and relevant information into the agent's context window.

The context window is divided into three main parts:

1. **System instructions and user information** (working memory)
2. **Recent messages** (conversation history)
3. **Older relevant messages** (semantic recall)

## Step Quiz
**Questions**
1) What is agent memory in Mastra used for?
**Answers**
1) To persist conversation context so the agent can reference past interactions.

<!-- STEP:02 -->
## Step 02: Why Memory Matters

# Why Memory Matters

Without memory, agents respond to each message in isolation, which can lead to repetitive questions and an inability to maintain context. With memory, your agents can:

- Remember previous user inputs and their own responses
- Recall user preferences and personal details
- Reference past conversations when relevant
- Provide more personalized and contextual responses
- Maintain state across multiple interactions

Memory transforms a basic chatbot into an intelligent assistant that feels like it truly understands and remembers its users. This creates a more natural and engaging user experience, as users don't have to repeat themselves or provide the same information multiple times.

## Step Quiz
**Questions**
1) Why does memory matter for agent quality?
**Answers**
1) It enables continuity and personalization across turns and sessions.

<!-- STEP:03 -->
## Step 03: Installing Memory

# Installing Memory

Let's start by installing the Mastra memory package:

```bash
npm install @mastra/memory@beta @mastra/libsql@beta
```

The `@mastra/memory` package provides all the functionality you need to add memory capabilities to your Mastra agents. It includes support for conversation history, semantic recall, and working memory.

The `@mastra/libsql` package is **one of many** storage adapters that complement the memory package. The purpose of a storage adapter is to provide a way to persist the memory data to a database or other storage system. The `@mastra/libsql` package provides a storage adapter for LibSQL, which is a fast, open-source fork of SQLite.

These packages are separate from the core Mastra package, allowing you to only include them when you need memory capabilities in your project. This modular approach helps keep your project dependencies lean when you don't need all features.

## Step Quiz
**Questions**
1) What is the key action in this step to enable memory?
**Answers**
1) Install the memory/storage dependency required by Mastra.

<!-- STEP:04 -->
## Step 04: Creating a Basic Memory Agent

# Creating a Basic Memory Agent

Now, let's create a simple agent with memory capabilities. We'll start with the basics and add more advanced features in the following steps.

Create or update your `src/mastra/agents/index.ts` file:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";

// Create a basic memory instance
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }),
});

// Create an agent with memory
export const memoryAgent = new Agent({
  name: "MemoryAgent",
  instructions: `
    You are a helpful assistant with memory capabilities.
    You can remember previous conversations and user preferences.
    When a user shares information about themselves, acknowledge it and remember it for future reference.
    If asked about something mentioned earlier in the conversation, recall it accurately.
  `,
  model: "openai/gpt-4.1-mini",
  memory: memory,
});
```

In this example, we're creating a basic `Memory` instance without any special configuration. This default configuration will still provide your agent with the ability to remember previous messages in the conversation.

The key part is adding the `memory` property to your agent configuration, which connects the memory instance to your agent.

## Step Quiz
**Questions**
1) What two components are configured when creating a basic memory agent?
**Answers**
1) A storage adapter (id/url) and an agent that references that memory config.

<!-- STEP:05 -->
## Step 05: Updating Your Mastra Export

# Updating Your Mastra Export

Make sure to update your `src/mastra/index.ts` file to include your new memory agent:

```typescript
import { Mastra } from "@mastra/core";
import { memoryAgent } from "./agents";

export const mastra: Mastra = new Mastra({
  agents: {
    memoryAgent,
  },
});
```

This step is essential for making your agent available in the Mastra playground. The `mastra` export is the main entry point for your Mastra application, and it needs to include all the agents you want to use.

By adding your `memoryAgent` to the `agents` object in the Mastra configuration, you're registering it with the Mastra system, making it available for use in the playground and other parts of your application.

## Step Quiz
**Questions**
1) Why update the Mastra export after creating the memory agent?
**Answers**
1) So the new agent is registered and available in the Mastra runtime.

<!-- STEP:06 -->
## Step 06: Testing Your Memory Agent

# Testing Your Memory Agent

Let's test our basic memory agent:

1. Make sure your development server is running with `npm run dev`
2. Open the playground at http://localhost:4111/
3. Select your "MemoryAgent" from the list of agents
4. Try having a conversation that tests basic memory capabilities:
   - "My name is Alex"
   - "What's my name?"
   - "I live in Seattle"
   - "Where do I live?"
   - "I prefer dark mode in my apps"
   - "What are my UI preferences?"

You should notice that your agent can remember information across these interactions. This is because the Mastra playground automatically handles the necessary resource and thread IDs for memory to work properly.

In the next step, we'll explore how to configure conversation history and understand how memory threads work.

## Step Quiz
**Questions**
1) How do you validate the memory agent works?
**Answers**
1) Ask follow-up questions and confirm it recalls earlier context.

<!-- STEP:07 -->
## Step 07: Managing Conversation History

# Managing Conversation History

In this step, we'll learn how to configure conversation history and understand memory threads in Mastra. Conversation history allows your agent to remember recent interactions, which is essential for maintaining context in ongoing conversations.

## Understanding Memory Threads

Mastra organizes memory into threads, which are records that identify specific conversation histories. Each thread uses two important identifiers:

1. **`threadId`**: A specific conversation ID (e.g., `support_123`)
2. **`resourceId`**: The user or entity ID that owns each thread (e.g., `user_alice`)

These identifiers allow memory to work properly outside of the playground. They help Mastra distinguish between different conversations and users, ensuring that the right memory is associated with the right conversation.

Without these identifiers, your agent would have no way to know which conversation history to retrieve when a user sends a message. The playground handles these identifiers automatically, but you'll need to manage them yourself when using memory in your own applications.

## Step Quiz
**Questions**
1) What does conversation history management control?
**Answers**
1) How many recent messages are retained and used for context.

<!-- STEP:08 -->
## Step 08: Configuring Conversation History

# Configuring Conversation History

By default, the `Memory` instance includes the last 10 messages from the current memory thread in each new request. You can customize this by configuring the `lastMessages` option:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";

// Create a memory instance with custom conversation history settings
const memory = new Memory({
  storage: new LibSQLStore({
    url: "file:../../memory.db",
  }),
  options: {
    lastMessages: 20, // Include the last 20 messages in the context instead of the default 10
  },
});

// Create an agent with the configured memory
export const memoryAgent = new Agent({
  name: "MemoryAgent",
  instructions: `
    You are a helpful assistant with memory capabilities.
    You can remember previous conversations and user preferences.
    When a user shares information about themselves, acknowledge it and remember it for future reference.
    If asked about something mentioned earlier in the conversation, recall it accurately.
  `,
  model: "openai/gpt-4.1-mini",
  memory: memory,
});
```

The `lastMessages` option controls how many of the most recent messages are included in the agent's context window. This is important because language models have a limited context window size, and including too many messages can push out other important information.

You'll want to balance between having enough context for the agent to understand the conversation and not overwhelming the context window with too much history.

## Step Quiz
**Questions**
1) What does the lastMessages option do?
**Answers**
1) It limits the number of recent messages stored in memory.

<!-- STEP:09 -->
## Step 09: Using Memory in Your Application

# Using Memory in Your Application

When using memory in your own application (outside the playground), you need to provide the `resourceId` and `threadId` with each agent call:

```typescript
// Example of using memory in your application
const response = await memoryAgent.stream("Hello, my name is Alice.", {
  resourceId: "user_alice",
  threadId: "conversation_123",
});
```

**Important:** Without these IDs, your agent will not use memory, even if memory is properly configured. The playground handles this for you, but you need to add IDs yourself when using memory in your application.

The `resourceId` should be a unique identifier for the user or entity that owns the conversation. This could be a user ID from your authentication system, an email address, or any other unique identifier.

The `threadId` should be a unique identifier for the specific conversation. This allows a single user to have multiple separate conversations with your agent, each with its own memory thread.

In a real application, you might generate these IDs when a user starts a new conversation and store them in your database or client-side storage to reuse in subsequent requests.

## Step Quiz
**Questions**
1) What identifiers are needed to use memory in your application?
**Answers**
1) A resourceId and a threadId to scope the conversation.

<!-- STEP:10 -->
## Step 10: Storage Configuration

# Storage Configuration

Conversation history relies on a storage adapter to persist messages. By default, Mastra uses a LibSQL store that saves messages to a local database. You can configure this or use other storage options:

```typescript
import { Memory } from "@mastra/memory";
import { LibSQLStore } from "@mastra/libsql";

const memory = new Memory({
  // Configure storage
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // Local database. Relative to the output folder
  }),
  options: {
    lastMessages: 20,
  },
});
```

Mastra supports several storage options, including:

- LibSQL (default, local SQLite)
- PostgreSQL
- Upstash (Redis)

The storage adapter is responsible for persisting memory data, including conversation history and working memory. This allows your agent to remember conversations even after your application restarts.

For development and testing, the default LibSQL store is usually sufficient. For production applications, you might want to use a more robust storage option like PostgreSQL or a cloud-based solution like Upstash.

## Step Quiz
**Questions**
1) What is the purpose of the storage configuration block?
**Answers**
1) To define where memory is stored (id/url) and how much history is kept.

<!-- STEP:11 -->
## Step 11: Testing Conversation History

# Testing Conversation History

Let's update our agent and test the conversation history capabilities:

1. Update your agent code with the configuration above
2. Restart your development server with `npm run dev`
3. Open the playground at http://localhost:4111/
4. Select your "MemoryAgent"
5. Try having a longer conversation with multiple turns:
   - "Let me tell you about my vacation plans"
   - "I'm planning to visit Japan next month"
   - "I'll be staying in Tokyo for a week"
   - "Then I'll visit Kyoto for three days"
   - "What were my vacation plans again?"

Your agent should be able to recall the details of your vacation plans because it maintains the conversation history.

This test demonstrates how conversation history allows your agent to maintain context throughout a multi-turn conversation. The agent can recall information from previous messages without requiring the user to repeat themselves.

Try extending the conversation even further to see how well your agent maintains context over a longer interaction. You can also experiment with different values for the `lastMessages` option to see how it affects your agent's ability to recall information from earlier in the conversation.

## Step Quiz
**Questions**
1) How do you test that conversation history works as expected?
**Answers**
1) Send multiple messages and verify the agent references recent ones.

<!-- STEP:12 -->
## Step 12: Handling Memory in Frontend Applications

# Handling Memory in Frontend Applications

When building a frontend application that uses Mastra memory, it's important to only send the newest user message in each agent call. Mastra handles retrieving and injecting the necessary history. Sending the full history yourself will cause duplication.

Here's a simplified example of how to handle this in a React application:

```tsx
import { useState } from "react";
import { memoryAgent } from "./agents";

function ChatApp() {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState("");

  const handleSendMessage = async () => {
    // Add user message to UI
    setMessages([...messages, { role: "user", content: input }]);

    // Only send the newest message to the agent
    const response = await memoryAgent.stream(input, {
      resourceId: "user_123",
      threadId: "conversation_456",
    });

    // Add agent response to UI
    setMessages([...messages, { role: "assistant", content: response }]);
    setInput("");
  };

  return (
    <div>
      {/* Display messages */}
      <div>
        {messages.map((msg, index) => (
          <div key={index}>
            <strong>{msg.role}:</strong> {msg.content}
          </div>
        ))}
      </div>

      {/* Input for new messages */}
      <input
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyPress={(e) => e.key === "Enter" && handleSendMessage()}
      />
      <button onClick={handleSendMessage}>Send</button>
    </div>
  );
}
```

This example demonstrates a common pattern for handling memory in a frontend application:

1. Store the conversation messages in the UI state for display purposes
2. When sending a message to the agent, only send the newest message
3. Include the `resourceId` and `threadId` with each agent call
4. Let Mastra handle retrieving and injecting the conversation history

This approach ensures that your agent has access to the conversation history without duplicating messages in the context window.

In the next step, we'll explore semantic recall, which allows your agent to remember information from older conversations that are no longer in the recent history.

## Step Quiz
**Questions**
1) What is the key responsibility of the frontend in memory handling?
**Answers**
1) Persist and pass threadId/resourceId with each message.

<!-- STEP:13 -->
## Step 13: Vector Store Configuration

# Vector Store Configuration

In addition to the memory storage adapters, Mastra also provides vector store adapters useful for storing and retrieving vector embeddings. One of these is the `LibSQLVector` adapter, which provides a simple interface for storing and retrieving vector embeddings in a LibSQL vector database.

```typescript
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }),
  vector: new LibSQLVector({
    id: "learning-memory-vector",
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }),
});
```

Mastra supports several vector store options, including:

- LibSQL
- Chroma
- Pinecone
- Qdrant
- Postgres (with pgvector)

The vector store is responsible for storing and retrieving the vector embeddings used for semantic search.

## Step Quiz
**Questions**
1) Why add a vector store configuration?
**Answers**
1) To enable semantic recall over past messages by embedding similarity.

<!-- STEP:14 -->
## Step 14: Implementing Semantic Recall

# Implementing Semantic Recall

One of the quickest ways to take advantage of the configured vector store is to use semantic recall.

## What is Semantic Recall?

Semantic recall is a RAG-based (Retrieval-Augmented Generation) search that allows your agent to find and retrieve relevant past conversations based on the current user query. It's similar to how a person would search their memory for relevant information when asked a question.

For example, if a user asks "What did we discuss about my project last week?", semantic recall helps the agent find and retrieve those specific conversations, even if they happened many messages ago.

Semantic recall extends your agent's memory beyond the limitations of the recent conversation history. While conversation history only includes the most recent messages, semantic recall can find and retrieve relevant information from any point in the conversation history, regardless of when it occurred.

## Step Quiz
**Questions**
1) What is semantic recall in this context?
**Answers**
1) Retrieving past messages by meaning using vector search.

<!-- STEP:15 -->
## Step 15: How Semantic Recall Works

# How Semantic Recall Works

Semantic recall uses vector embeddings of messages for similarity search. When a user sends a message, the system:

1. Creates an embedding (vector representation) of the message
2. Searches for similar message embeddings in the history
3. Retrieves the most relevant messages
4. Includes those messages and their surrounding context in the agent's context window

This allows the agent to "remember" relevant information from past conversations, even if they're not in the recent message history.

The embedding process converts text into a high-dimensional vector that captures the semantic meaning of the message. Messages with similar meanings will have similar vector representations, allowing the system to find relevant past messages even if they use different wording.

For example, if a user previously mentioned "I'm working on a project with a deadline next month" and later asks "When is my project due?", semantic recall can find the earlier message based on the semantic similarity between the question and the stored information.

## Step Quiz
**Questions**
1) How does semantic recall decide what to retrieve?
**Answers**
1) By embedding the query and selecting the most similar past messages.

<!-- STEP:16 -->
## Step 16: Configuring Semantic Recall

# Configuring Semantic Recall

Let's update our agent with custom semantic recall settings:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

// Create a memory instance with semantic recall configuration
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }), // Storage for message history
  vector: new LibSQLVector({
    id: "learning-memory-vector",
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }), // Vector database for semantic search
  embedder: "openai/text-embedding-3-small", // Embedder for message embeddings
  options: {
    lastMessages: 20, // Include the last 20 messages in the context
    semanticRecall: true, // Enable semantic recall with default settings
  },
});

// Create an agent with the configured memory
export const memoryAgent = new Agent({
  name: "MemoryAgent",
  instructions: `
    You are a helpful assistant with advanced memory capabilities.
    You can remember previous conversations and user preferences.
    When a user shares information about themselves, acknowledge it and remember it for future reference.
    If asked about something mentioned earlier in the conversation, recall it accurately.
    You can also recall relevant information from older conversations when appropriate.
  `,
  model: "openai/gpt-4.1-mini",
  memory: memory,
});
```

For semantic recall to work, you need to have a **vector store** configured. You also need to have an **embedder** configured. You may use any compatible embedding model for this. In this example, we're using OpenAI's `openai/text-embedding-3-small` model.

## Step Quiz
**Questions**
1) What settings are required to turn on semantic recall?
**Answers**
1) A vector store, an embedder, and semanticRecall options in memory config.

<!-- STEP:17 -->
## Step 17: Testing Semantic Recall

# Testing Semantic Recall

Let's test our agent's semantic recall capabilities:

1. Update your agent code with the configuration above
2. Restart your development server with `npm run dev`
3. Open the playground at http://localhost:4111/
4. Select your "MemoryAgent"
5. Have a conversation with multiple topics:
   - "Let's talk about my work project first"
   - "I'm working on a new website for a client"
   - "The deadline is in two weeks"
   - "Now let's switch topics. I'm also planning a vacation"
   - "I'll be visiting Japan next month"
   - "I'll be staying in Tokyo and Kyoto"
   - "Let's talk about something else. I'm learning to play guitar"
   - "I practice for 30 minutes every day"
   - "Can you remind me about my work project deadline?"

Your agent should be able to recall the project deadline information, even though it was mentioned several messages ago and the conversation has moved on to other topics.

This test demonstrates how semantic recall allows your agent to find and retrieve relevant information from earlier in the conversation, even when that information is no longer included in the recent conversation history.

Try asking about other topics you discussed earlier to see how well your agent can retrieve different pieces of information. You can also experiment with different values for the `topK` and `messageRange` parameters to see how they affect your agent's ability to recall information.

## Step Quiz
**Questions**
1) What does a successful semantic recall test look like?
**Answers**
1) The agent pulls in relevant past info that isn't in the recent window.

<!-- STEP:18 -->
## Step 18: Advanced Configuration of Semantic Recall

# Advanced Configuration of Semantic Recall

We can configure semantic recall in more detail by setting options for the `semanticRecall` option:

```typescript
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }),
  vector: new LibSQLVector({
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }),
  embedder: openai.embedding("text-embedding-3-small"),
  options: {
    semanticRecall: {
      topK: 3,
      messageRange: {
        before: 2,
        after: 1,
      },
    },
  },
});
```

The `topK` parameter controls how many semantically similar messages are retrieved. A higher value will retrieve more messages, which can be helpful for complex topics but may also include less relevant information. The default value is `4`.

The `messageRange` parameter controls how much context is included with each match. This is important because the matching message alone might not provide enough context to understand the conversation. Including messages before and after the match helps the agent understand the context of the matched message.

## Step Quiz
**Questions**
1) What do topK and messageRange control in advanced recall?
**Answers**
1) How many matches to retrieve and how many neighboring messages to include.

<!-- STEP:19 -->
## Step 19: Implementing Working Memory

# Implementing Working Memory

In this step, we'll explore working memory, which allows your agent to maintain persistent information about users across interactions within a thread.

## What is Working Memory?

Working memory is like your agent's active thoughts or scratchpad – it's the key information they keep available about the user or task. It's similar to how a person would naturally remember someone's name, preferences, or important details during a conversation.

Unlike conversation history and semantic recall, which focus on remembering past messages, working memory is designed to store structured information that's continuously relevant, such as:

- User profile information (name, location, preferences)
- Task-specific details (project goals, deadlines)
- Session state (current topic, open questions)

Working memory provides a way for your agent to maintain a persistent understanding of the user and the context of the conversation, even as the specific messages in the conversation history change. This allows your agent to provide more personalized and contextual responses over time.

## Step Quiz
**Questions**
1) What is working memory designed to store?
**Answers**
1) Stable user-specific facts or preferences that should persist.

<!-- STEP:20 -->
## Step 20: How Working Memory Works

# How Working Memory Works

Working memory is implemented as a block of Markdown text that the agent can update over time. The agent reads this information at the beginning of each conversation and can update it as new information becomes available.

When a user shares information that should be remembered long-term (like their name, location, or preferences), the agent can update the working memory to include this information. In subsequent conversations, the agent will have access to this information without the user having to repeat it.

The working memory is stored in a structured format, typically as Markdown, which makes it easy for the agent to read and update. This structure helps guide the agent on what information to track and how to organize it.

Unlike conversation history, which is a record of the actual messages exchanged, working memory is a distilled summary of the important information the agent has learned about the user or task. This makes it more efficient and focused than trying to extract this information from the raw conversation history.

## Step Quiz
**Questions**
1) How does working memory differ from semantic recall?
**Answers**
1) Working memory stores curated facts; semantic recall retrieves by similarity.

<!-- STEP:21 -->
## Step 21: Configuring Working Memory

# Configuring Working Memory

Let's update our agent with working memory capabilities:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

// Create a memory instance with working memory configuration
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }), // Storage for message history
  vector: new LibSQLVector({
    id: "learning-memory-vector",
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }), // Vector database for semantic search
  embedder: "openai/text-embedding-3-small", // Embedder for message embeddings
  options: {
    semanticRecall: {
      topK: 3,
      messageRange: {
        before: 2,
        after: 1,
      },
    },
    workingMemory: {
      enabled: true,
    },
  },
});

// Create an agent with the configured memory
export const memoryAgent = new Agent({
  name: "MemoryAgent",
  instructions: `
    You are a helpful assistant with advanced memory capabilities.
    You can remember previous conversations and user preferences.
    
    IMPORTANT: You have access to working memory to store persistent information about the user.
    When you learn something important about the user, update your working memory.
    This includes:
    - Their name
    - Their location
    - Their preferences
    - Their interests
    - Any other relevant information that would help personalize the conversation
    
    Always refer to your working memory before asking for information the user has already provided.
    Use the information in your working memory to provide personalized responses.
  `,
  model: "openai/gpt-4.1-mini",
  memory: memory,
});
```

The `workingMemory` configuration has several important options:

- `enabled`: Whether working memory is enabled
- `template`: A template for the working memory content

The instructions for the agent are also important. They guide the agent on what information to store in working memory and how to use that information when responding to the user.

## Step Quiz
**Questions**
1) Which config flag enables working memory?
**Answers**
1) workingMemory.enabled set to true in the memory options.

<!-- STEP:22 -->
## Step 22: Custom Working Memory Templates

# Custom Working Memory Templates

Templates guide the agent on what information to track and update in working memory. While a default template is used if none is provided, you'll typically want to define a custom template tailored to your agent's specific use case.

Let's update our agent with a custom working memory template:

```typescript
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";

// Create a memory instance with a custom working memory template
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }), // Storage for message history
  vector: new LibSQLVector({
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }), // Vector database for semantic search
  embedder: "openai/text-embedding-3-small", // Embedder for message embeddings
  options: {
    semanticRecall: {
      topK: 3,
      messageRange: {
        before: 2,
        after: 1,
      },
    },
    workingMemory: {
      enabled: true,
    },
    workingMemory: {
      enabled: true,
      template: `
# User Profile

## Personal Info

- Name:
- Location:
- Timezone:

## Preferences

- Communication Style: [e.g., Formal, Casual]
- Interests:
- Favorite Topics:

## Session State

- Current Topic:
- Open Questions:
  - [Question 1]
  - [Question 2]
`,
    },
  },
});

// Create an agent with the configured memory
export const memoryAgent = new Agent({
  name: "MemoryAgent",
  instructions: `
    You are a helpful assistant with advanced memory capabilities.
    You can remember previous conversations and user preferences.
    
    IMPORTANT: You have access to working memory to store persistent information about the user.
    When you learn something important about the user, update your working memory according to the template.
    
    Always refer to your working memory before asking for information the user has already provided.
    Use the information in your working memory to provide personalized responses.
    
    When the user shares personal information such as their name, location, or preferences,
    acknowledge it and update your working memory accordingly.
  `,
  model: "openai/gpt-4.1-mini",
  memory: memory,
});
```

The template is a Markdown document that defines the structure of the working memory. It includes sections for different types of information, such as personal info, preferences, and session state.

The template serves several important purposes:

1. It guides the agent on what information to track and how to organize it
2. It provides a consistent structure for the working memory across conversations
3. It makes it easier for the agent to find and update specific pieces of information

You should design your template based on the specific needs of your agent and the type of information it needs to remember about users or tasks.

## Step Quiz
**Questions**
1) Why create a custom working memory template?
**Answers**
1) To define the structured fields you want the agent to persist.

<!-- STEP:23 -->
## Step 23: Testing Working Memory

# Testing Working Memory

Let's test our agent's working memory capabilities:

1. Update your agent code with the configuration above
2. Restart your development server with `npm run dev`
3. Open the playground at http://localhost:4111/
4. Select your "MemoryAgent"
5. Have a conversation that reveals personal information:
   - "Hi, my name is Jordan"
   - "I live in Toronto, Canada"
   - "I prefer casual communication"
   - "I'm interested in artificial intelligence and music production"
   - "What do you know about me so far?"

Your agent should be able to recall all this information from its working memory, even if the conversation has moved on to other topics.

6. Continue the conversation with new topics, then ask again:
   - "Let's talk about the latest AI developments"
   - (Have a conversation about AI)
   - "What was my name again and where do I live?"

The agent should still remember this information because it's stored in working memory, not just in the conversation history.

This test demonstrates how working memory allows your agent to maintain persistent information about the user across different topics and conversation turns. Unlike conversation history, which only includes recent messages, working memory provides a structured way to store and retrieve important information about the user regardless of when it was mentioned.

## Step Quiz
**Questions**
1) How do you test working memory?
**Answers**
1) Provide user facts and verify they are retained in later queries.

<!-- STEP:24 -->
## Step 24: Working Memory in Practice

# Working Memory in Practice

Working memory is particularly useful for:

1. **Personal assistants** that need to remember user preferences
2. **Customer support agents** that need to track issue details
3. **Educational agents** that need to remember a student's progress
4. **Task-oriented agents** that need to track the state of a complex task

By using working memory effectively, you can create agents that feel more personalized and attentive to user needs.

Here are some best practices for using working memory effectively:

1. **Be selective about what goes into working memory**
   - Focus on information that will be relevant across multiple conversations
   - Don't overload working memory with transient details

2. **Use clear instructions**
   - Give your agent explicit guidance on when and how to update working memory
   - Instruct it to check memory before asking for information the user has already provided

3. **Design a thoughtful template**
   - Structure your template based on the specific needs of your agent
   - Include sections for different types of information
   - Use clear labels and organization to make information easy to find

4. **Test thoroughly**
   - Verify that your agent correctly updates and retrieves information from working memory
   - Test edge cases like conflicting information or corrections

In the next step, we'll bring everything together to create a complete memory-enhanced agent with all the features we've explored.

## Step Quiz
**Questions**
1) What is the goal of the 'Working Memory in Practice' step?
**Answers**
1) Apply working memory to a realistic workflow or user scenario.

<!-- STEP:25 -->
## Step 25: Building a Complete Memory-Enhanced Agent

# Building a Complete Memory-Enhanced Agent

In this final step, we'll bring together all the memory features we've explored to create a complete memory-enhanced agent. We'll also create a practical example that demonstrates how these features work together.

## Combining All Memory Features

Let's create a comprehensive agent that utilizes conversation history, semantic recall, and working memory:

```typescript
// src/mastra/agents/memory-agent.ts
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

// Create a comprehensive memory configuration
const memory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }),
  vector: new LibSQLVector({
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }),
  embedder: "openai/text-embedding-3-small",
  options: {
    // Conversation history configuration
    lastMessages: 20, // Include the last 20 messages in the context

    // Semantic recall configuration
    semanticRecall: {
      topK: 3, // Retrieve 3 most similar messages
      messageRange: {
        before: 2, // Include 2 messages before each match
        after: 1, // Include 1 message after each match
      },
    },

    // Working memory configuration
    workingMemory: {
      enabled: true,
      template: `
# User Profile

## Personal Info
- Name:
- Location:
- Timezone:
- Occupation:

## Preferences
- Communication Style:
- Topics of Interest:
- Learning Goals:

## Project Information
- Current Projects:
  - [Project 1]:
    - Deadline:
    - Status:
  - [Project 2]:
    - Deadline:
    - Status:

## Session State
- Current Topic:
- Open Questions:
- Action Items:
`,
    },
  },
});
```

This comprehensive memory configuration combines all three memory features we've explored:

1. **Conversation history** with the `lastMessages` option
2. **Semantic recall** with the `semanticRecall` option
3. **Working memory** with the `workingMemory` option

Each feature serves a different purpose in enhancing your agent's memory capabilities, and together they create a powerful memory system that can maintain context across conversations and provide personalized responses.

## Step Quiz
**Questions**
1) What does the complete memory configuration combine?
**Answers**
1) Conversation history, semantic recall, and working memory in one agent.

<!-- STEP:26 -->
## Step 26: updating mastra export comprehensive

## Step Quiz
**Questions**
1) Why update the Mastra export again in this step?
**Answers**
1) To register the comprehensive memory agent so it can be used.

<!-- STEP:27 -->
## Step 27: Creating a Practical Example: Personal Learning Assistant

# Creating a Practical Example: Personal Learning Assistant

Let's create a practical example of a memory-enhanced agent: a Personal Learning Assistant that helps users learn new skills and tracks their progress.

```typescript
// src/mastra/agents/learning-assistant.ts
import { Agent } from "@mastra/core/agent";
import { Memory } from "@mastra/memory";
import { LibSQLStore, LibSQLVector } from "@mastra/libsql";

// Create a specialized memory configuration for the learning assistant
const learningMemory = new Memory({
  storage: new LibSQLStore({
    id: "learning-memory-storage",
    url: "file:../../memory.db", // relative path from the `.mastra/output` directory
  }),
  vector: new LibSQLVector({
    connectionUrl: "file:../../vector.db", // relative path from the `.mastra/output` directory
  }),
  embedder: "openai/text-embedding-3-small",
  options: {
    lastMessages: 20,
    semanticRecall: {
      topK: 3,
      messageRange: {
        before: 2,
        after: 1,
      },
    },
    workingMemory: {
      enabled: true,
      template: `
# Learner Profile

## Personal Info
- Name:
- Learning Style: [Visual, Auditory, Reading/Writing, Kinesthetic]

## Learning Journey
- Current Topics:
  - [Topic 1]:
    - Skill Level: [Beginner, Intermediate, Advanced]
    - Started: [Date]
    - Goals:
    - Resources:
    - Progress Notes:
  - [Topic 2]:
    - Skill Level: [Beginner, Intermediate, Advanced]
    - Started: [Date]
    - Goals:
    - Resources:
    - Progress Notes:

## Session State
- Current Focus:
- Questions to Revisit:
- Recommended Next Steps:
`,
    },
  },
});

// Create the learning assistant agent
export const learningAssistantAgent = new Agent({
  name: "Learning Assistant",
  instructions: `
    You are a personal learning assistant that helps users learn new skills and tracks their progress.
    
    ## Your Capabilities
    
    - You help users set learning goals and track their progress
    - You provide explanations and resources tailored to their skill level
    - You remember what topics they're learning and their progress in each
    - You adapt your teaching style to match their learning preferences
    
    ## Guidelines for Using Memory
    
    - When the user shares information about their learning style or preferences,
      update your working memory.
    
    - When the user asks about a topic they've mentioned before, use your semantic
      recall to provide continuity in your teaching.
    
    - When explaining concepts, check your working memory to understand their
      current skill level and provide an explanation at the appropriate depth.
    
    Always be encouraging and supportive. Focus on building the user's confidence
    and celebrating their progress.
  `,
  model: "openai/gpt-4.1-mini",
  memory: learningMemory,
});

// Don't forget to export this agent in your src/mastra/index.ts file
```

This example demonstrates how to create a specialized agent with a memory configuration tailored to a specific use case. The Learning Assistant uses:

1. A custom working memory template designed to track learning progress
2. Specialized instructions that guide the agent on how to use memory for educational purposes
3. All three memory features (conversation history, semantic recall, and working memory) working together

This type of specialized agent can provide a much more personalized and effective learning experience compared to a generic chatbot without memory capabilities.

## Step Quiz
**Questions**
1) What is the purpose of the Personal Learning Assistant example?
**Answers**
1) To demonstrate a real agent using full memory features.

<!-- STEP:28 -->
## Step 28: Testing Your Memory-Enhanced Agents

# Testing Your Memory-Enhanced Agents

Let's test both of our memory-enhanced agents:

1. Make sure your development server is running with `npm run dev`
2. Open the playground at `http://localhost:4111/`

## Testing the Memory Master Agent

1. Select your `MemoryMasterAgent`
2. Have a comprehensive conversation that tests all memory features:
   - Share personal information: "Hi, I'm Taylor. I live in Boston and work as a software engineer."
   - Discuss a project: "I'm working on a web application with a deadline next month."
   - Switch topics: "Let's talk about my vacation plans for the summer."
   - Return to the previous topic: "Remind me, what was the deadline for my web application?"
   - Ask about personal information: "What do you know about me so far?"

## Testing the Learning Assistant

1. Select your `Learning Assistant`
2. Have a conversation about learning programming:
   - "I want to learn Python programming. I'm a complete beginner."
   - "My learning style is visual - I learn best with diagrams and examples."
   - "Can you explain variables and data types in Python?"
   - "Now I'd like to learn about functions."
   - "Let's switch topics. I'm also interested in learning web development."
   - "I have some experience with HTML and CSS already."
   - "Can you go back to Python? I forgot how functions work."

Your agents should demonstrate all the memory capabilities we've explored:

- Remembering recent conversation context
- Recalling relevant information from older messages
- Maintaining persistent user information in working memory
- Using this information to provide personalized and contextual responses

These tests help verify that your memory-enhanced agents are working as expected and can effectively use all three memory features. Pay attention to how the agents handle context switches, recall information from earlier in the conversation, and maintain persistent information about the user or task.

## Step Quiz
**Questions**
1) What should you verify when testing memory-enhanced agents?
**Answers**
1) That they recall context and use stored preferences correctly.

<!-- STEP:29 -->
## Step 29: Memory Best Practices

# Memory Best Practices

As you build memory-enhanced agents, keep these best practices in mind:

1. **Be selective about what goes into working memory**
   - Focus on information that will be relevant across multiple conversations
   - Don't overload working memory with transient details

2. **Use clear instructions**
   - Give your agent explicit guidance on when and how to update working memory
   - Instruct it to check memory before asking for information the user has already provided

3. **Choose appropriate memory parameters**
   - Adjust `lastMessages`, `topK`, and `messageRange` based on your use case
   - More isn't always better - larger context windows can dilute focus

4. **Consider privacy implications**
   - Be transparent with users about what information is being stored
   - Implement appropriate security measures for sensitive information

5. **Test thoroughly**
   - Verify that your agent correctly recalls information across different scenarios
   - Test edge cases like conflicting information or corrections

6. **Design thoughtful templates**
   - Structure your working memory templates based on your agent's specific needs
   - Include clear sections and organization to make information easy to find

7. **Balance memory types**
   - Use conversation history for recent context
   - Use semantic recall for finding relevant past information
   - Use working memory for persistent user details and state

By following these best practices, you can create memory-enhanced agents that provide truly personalized and contextual experiences while avoiding common pitfalls like information overload, privacy concerns, and inconsistent behavior.

## Step Quiz
**Questions**
1) Name one memory best practice highlighted here.
**Answers**
1) Keep memory scoped, test recall, or avoid storing irrelevant data.

<!-- STEP:30 -->
## Step 30: Conclusion

# Conclusion

Congratulations! You've learned how to create sophisticated memory-enhanced agents using Mastra. You now understand:

- How to configure conversation history to maintain recent context
- How to implement semantic recall to find relevant past conversations
- How to use working memory to maintain persistent user information
- How to combine these features into comprehensive memory-enhanced agents

With these skills, you can create agents that provide truly personalized and contextual experiences for your users. Memory is what transforms a simple chatbot into an intelligent assistant that feels like it truly understands and remembers its users.

Continue experimenting with different memory configurations and templates to find what works best for your specific use cases. The more tailored your memory approach is to your agent's purpose, the more effective it will be.

Here are some ideas for further exploration:

1. **Specialized agents** - Create agents with memory configurations tailored to specific domains like customer support, education, or personal productivity
2. **Advanced templates** - Design more sophisticated working memory templates for complex use cases
3. **Integration with other features** - Combine memory with other Mastra features like workflows and evals
4. **Production deployment** - Configure persistent storage options for memory in production environments

Remember that effective memory is about more than just storing information—it's about retrieving the right information at the right time to provide helpful, contextual, and personalized responses to users.

## Step Quiz
**Questions**
1) What is the main takeaway of the conclusion?
**Answers**
1) Memory features combine to create personalized, context-aware agents.
